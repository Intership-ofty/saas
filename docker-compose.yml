version: '3.8'

services:
  # ==================== SERVICE PRINCIPAL API/DASHBOARD ====================
  api-dashboard-service:
    build:
      context: ./api-dashboard-service
      dockerfile: Dockerfile
    container_name: api-dashboard-service
    ports:
      - "10005:8000"
    environment:
      - DATABASE_URL=postgresql://warehouse_user:warehouse_password@warehouse-service:5432/data_warehouse
      - NIFI_SERVICE_URL=http://nifi-service:8080
      - DBT_SERVICE_URL=http://dbt-service:8001
      - RECONCILIATION_SERVICE_URL=http://reconciliation-service:8002
      - QUALITY_CONTROL_SERVICE_URL=http://quality-control-service:8003
      - RCA_SERVICE_URL=http://rca-service:8004
      - SECRET_KEY=your-secret-key-here-change-in-production
      - DEBUG=false
    depends_on:
      - warehouse-service
    networks:
      - saas-network
    volumes:
      - ./api-dashboard-service/app:/app
      - ./data/dashboard:/app/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==================== SERVICE NIFI POUR INGESTION ====================
  nifi-service:
    build:
      context: ./nifi-service
      dockerfile: Dockerfile
    container_name: nifi-service
    ports:
      - "8080:8080"
      # - "8443:8443"
      # - "11000:10000"
      # - "8000:8000"
    environment:
      - NIFI_WEB_HTTP_HOST=0.0.0.0
      # - NIFI_WEB_HTTP_PORT=8080
      # - NIFI_SENSITIVE_PROPS_KEY=changeme123456789012345678901234567890
      # - NIFI_WEB_HTTP_HOST=0.0.0.0
      # - NIFI_WEB_HTTP_PORT=8080
      # - NIFI_WEB_HTTPS_HOST=0.0.0.0
      #- NIFI_WEB_HTTPS_PORT=8443
      # - NIFI_CLUSTER_IS_NODE=false
      # - NIFI_SENSITIVE_PROPS_KEY=changeme123456789012345678901234567890
      # - NIFI_RUN_AS_USER=
    networks:
      - saas-network
    # volumes:
      # - ./nifi-service/nifi-conf:/opt/nifi/nifi-current/conf
      # - ./data/nifi/database_repository:/opt/nifi/nifi-current/database_repository
      # - ./data/nifi/flowfile_repository:/opt/nifi/nifi-current/flowfile_repository
      # - ./data/nifi/content_repository:/opt/nifi/nifi-current/content_repository
      # - ./data/nifi/provenance_repository:/opt/nifi/nifi-current/provenance_repository
      # - ./data/nifi/logs:/opt/nifi/nifi-current/logs
      # - ./data/minio:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/nifi/"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==================== SERVICE DBT POUR TRANSFORMATION ====================
  dbt-service:
    build:
      context: ./dbt-service
      dockerfile: Dockerfile
    container_name: dbt-service
    ports:
      - "8001:8001"
    environment:
      - DATABASE_URL=postgresql://warehouse_user:warehouse_password@warehouse-service:5432/data_warehouse
      - PYTHONPATH=/app
      - DEBUG=false
    depends_on:
      - warehouse-service
    networks:
      - saas-network
    volumes:
      - ./dbt-service/app:/app
      - ./data/dbt:/app/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==================== SERVICE RÉCONCILIATION ZINGG ====================
  reconciliation-service:
    build:
      context: ./reconciliation-service
      dockerfile: Dockerfile
    container_name: reconciliation-service
    ports:
      - "8002:8002"
    environment:
      - DATABASE_URL=postgresql://warehouse_user:warehouse_password@warehouse-service:5432/data_warehouse
      - PYTHONPATH=/app
      - ZINGG_WORKSPACE=/tmp/zingg_workspace
      - ZINGG_MODEL_PATH=/tmp/zingg_models
      - DEBUG=false
    depends_on:
      - warehouse-service
    networks:
      - saas-network
    volumes:
      - ./reconciliation-service/app:/app
      - ./data/zingg_workspace:/tmp/zingg_workspace
      - ./data/zingg_models:/tmp/zingg_models
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==================== SERVICE CONTRÔLE QUALITÉ SODA ====================
  quality-control-service:
    build:
      context: ./quality-control-service
      dockerfile: Dockerfile
    container_name: quality-control-service
    ports:
      - "8003:8003"
    environment:
      - DATABASE_URL=postgresql://warehouse_user:warehouse_password@warehouse-service:5432/data_warehouse
      - PYTHONPATH=/app
      - SODA_CONFIG_PATH=/app/soda_config
      - SODA_CHECKS_PATH=/app/soda_checks
      - DEBUG=false
    depends_on:
      - warehouse-service
    networks:
      - saas-network
    volumes:
      - ./quality-control-service/app:/app
      - ./data/soda_config:/app/soda_config
      - ./data/soda_checks:/app/soda_checks
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8003/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==================== SERVICE RCA POUR ANALYSE DES CAUSES RACINES ====================
  rca-service:
    build:
      context: ./rca-service
      dockerfile: Dockerfile
    container_name: rca-service
    ports:
      - "8004:8004"
    environment:
      - DATABASE_URL=postgresql://warehouse_user:warehouse_password@warehouse-service:5432/data_warehouse
      - PYTHONPATH=/app
      - DEBUG=false
    depends_on:
      - warehouse-service
    networks:
      - saas-network
    volumes:
      - ./rca-service/app:/app
      - ./data/rca:/app/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8004/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==================== SERVICE WAREHOUSE POSTGRESQL ====================
  warehouse-service:
    build:
      context: ./warehouse-service
      dockerfile: Dockerfile
    container_name: warehouse-service
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_DB=data_warehouse
      - POSTGRES_USER=warehouse_user
      - POSTGRES_PASSWORD=warehouse_password
      - POSTGRES_INITDB_ARGS=--encoding=UTF-8 --lc-collate=C --lc-ctype=C
    networks:
      - saas-network
    volumes:
      - ./data/postgres:/var/lib/postgresql/data
      - ./warehouse-service/init.sql:/docker-entrypoint-initdb.d/init.sql:ro
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U warehouse_user -d data_warehouse"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ==================== REDIS POUR CACHE ET SESSIONS ====================
  redis:
    image: redis:7-alpine
    container_name: redis-cache
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    networks:
      - saas-network
    volumes:
      - ./data/redis:/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  # ==================== NGINX POUR REVERSE PROXY ====================
  nginx:
    image: nginx:alpine
    container_name: nginx-proxy
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
    depends_on:
      - api-dashboard-service
      - nifi-service
    networks:
      - saas-network
    restart: unless-stopped

  # ==================== PROMETHEUS POUR MONITORING ====================
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./data/prometheus:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--storage.tsdb.retention.time=15d'
      - '--storage.tsdb.retention.size=10GB'
    networks:
      - saas-network
    restart: unless-stopped

  # ==================== GRAFANA POUR VISUALISATION ====================
  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - ./data/grafana:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/datasources:/etc/grafana/provisioning/datasources:ro
    depends_on:
      - prometheus
    networks:
      - saas-network
    restart: unless-stopped

  # ==================== KAFKA POUR STREAMING (MODE KRAFT) ====================
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka
    ports:
      - "9092:9092"
      - "9093:9093"
    environment:
      # Configuration KRaft (sans ZooKeeper)
      - CLUSTER_ID=4L6g3nShT-eMCtK--X86sw
      - KAFKA_NODE_ID=1
      - KAFKA_PROCESS_ROLES=broker,controller
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_INTER_BROKER_LISTENER_NAME=PLAINTEXT
      - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_AUTO_CREATE_TOPICS_ENABLE=true
      - KAFKA_LOG_RETENTION_HOURS=168
    networks:
      - saas-network
    volumes:
      - kafka-data:/var/lib/kafka/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ==================== MINIO POUR STOCKAGE OBJET (OPTIONNEL) ====================
  minio:
    image: minio/minio:latest
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin123
    command: server /data --console-address ":9001"
    networks:
      - saas-network
    volumes:
      - ./data/minio:/data
    restart: unless-stopped

# ==================== RÉSEAUX ====================
networks:
  saas-network:
    driver: bridge
#    ipam:
#      config:
#        - subnet: 172.20.0.0/16

# ==================== VOLUMES ====================
volumes:
  kafka-data:
    driver: local
