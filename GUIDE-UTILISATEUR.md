# üìñ GUIDE UTILISATEUR - Plateforme SaaS Data Platform

## üéØ Vue d'ensemble

Cette plateforme SaaS offre une solution compl√®te de traitement et d'analyse de donn√©es avec une interface centralis√©e pour orchestrer tous les services. Elle permet d'ing√©rer, transformer, r√©concilier, contr√¥ler la qualit√© et analyser les donn√©es depuis une interface web unique.

## üöÄ Acc√®s √† la Plateforme

### URLs Principales

| Service | URL | Description | Identifiants |
|---------|-----|-------------|--------------|
| **Dashboard Principal** | http://localhost | Interface web centralis√©e | - |
| **Documentation API** | http://localhost/docs | Documentation Swagger interactive | - |
| **NiFi (Ingestion)** | http://localhost/nifi | Interface d'ingestion de donn√©es | - |
| **Grafana (Monitoring)** | http://localhost/grafana | Dashboards de monitoring | admin/admin |
| **Prometheus (M√©triques)** | http://localhost/prometheus | M√©triques syst√®me | - |

### D√©marrage Rapide

```bash
# 1. D√©marrer la plateforme
docker-compose up -d

# 2. V√©rifier le statut
docker-compose ps

# 3. Acc√©der au dashboard
# Ouvrir http://localhost dans votre navigateur
```

## üè† Interface Principale - Dashboard Central

### Widgets Disponibles

Le dashboard principal propose 5 widgets configurables :

#### 1. **√âtat des Services** (System Health)
- **Fonction** : Monitoring en temps r√©el de tous les services
- **Donn√©es** : Statut (healthy/unhealthy/unreachable) de chaque service
- **Services surveill√©s** :
  - nifi-service (Ingestion)
  - dbt-service (Transformation)
  - reconciliation-service (R√©conciliation)
  - quality-control-service (Contr√¥le qualit√©)
  - rca-service (Analyse RCA)
  - warehouse-service (Base de donn√©es)

#### 2. **Score de Qualit√©** (Data Quality)
- **Fonction** : Score global de qualit√© des donn√©es
- **M√©triques** :
  - Compl√©tude : 98.2%
  - Pr√©cision : 96.8%
  - Consistance : 94.5%
  - Validit√© : 97.1%
- **Tendance** : √âvolution du score dans le temps

#### 3. **D√©bit de Traitement** (Processing Throughput)
- **Fonction** : Volume de donn√©es trait√©es par minute
- **Unit√©** : records/min
- **Historique** : Graphique temporel des performances

#### 4. **Taux d'Erreur** (Error Rate)
- **Fonction** : Surveillance des erreurs syst√®me
- **Unit√©** : Pourcentage
- **Seuils** : Alertes automatiques si > 5%

#### 5. **R√©sum√© KPI** (KPI Summary)
- **Fonction** : Indicateurs cl√©s de performance
- **M√©triques** :
  - Qualit√© : 95.5%
  - D√©bit : 1250 rec/min
  - Erreurs : 0.5%
  - Uptime : 99.9%

### Configuration du Dashboard

```bash
# Personnaliser la disposition des widgets
curl -X GET "http://localhost/dashboard/config"

# Sauvegarder une nouvelle configuration
curl -X POST "http://localhost/dashboard/config" \
  -H "Content-Type: application/json" \
  -d '{
    "layout": "grid",
    "refresh_interval": 30,
    "widgets": [...]
  }'
```

## üîÑ Workflows d'Utilisation

### 1. **Workflow d'Ingestion de Donn√©es**

#### Via l'Interface Web (Recommand√©)
1. **Acc√©der √† NiFi** : http://localhost/nifi
2. **Cr√©er un flux** : Glisser-d√©poser les processeurs
3. **Configurer les sources** : CRM, ERP, fichiers, APIs
4. **D√©marrer le flux** : Bouton "Start" sur le processeur

#### Via l'API REST
```bash
# Ingestion directe via API
curl -X POST "http://localhost/data/ingest" \
  -H "Content-Type: application/json" \
  -d '[
    {
      "id": "1",
      "name": "John Doe",
      "email": "john@example.com",
      "value": 100.50,
      "source": "CRM"
    }
  ]'
```

### 2. **Workflow de Transformation des Donn√©es**

#### Via l'API DBT Service
```bash
# Transformation avec normalisation
curl -X POST "http://localhost:8001/transform" \
  -H "Content-Type: application/json" \
  -d '{
    "data": [...],
    "transformation_type": "normalize",
    "parameters": {
      "normalize_numeric": true,
      "trim_strings": true,
      "standardize_dates": true
    }
  }'

# Calcul de KPI
curl -X POST "http://localhost:8001/kpi/calculate" \
  -H "Content-Type: application/json" \
  -d '{
    "data": [...],
    "kpi_type": "revenue_metrics",
    "time_period": "monthly"
  }'
```

### 3. **Workflow de Contr√¥le Qualit√©**

#### Via l'API Quality Control Service
```bash
# V√©rification compl√®te de qualit√©
curl -X POST "http://localhost:8003/check" \
  -H "Content-Type: application/json" \
  -d '{
    "data": [...],
    "quality_rules": [
      {
        "type": "required_field",
        "field": "email",
        "severity": "error"
      },
      {
        "type": "format_validation",
        "field": "email",
        "pattern": "^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}$"
      }
    ],
    "check_completeness": true,
    "check_validity": true,
    "check_consistency": true
  }'

# D√©tection d'anomalies
curl -X POST "http://localhost:8003/detect-anomalies" \
  -H "Content-Type: application/json" \
  -d '{
    "data": [...],
    "anomaly_types": ["statistical", "pattern", "outlier"],
    "sensitivity": 0.8
  }'
```

### 4. **Workflow de R√©conciliation**

#### Via l'API Reconciliation Service
```bash
# R√©conciliation d'entit√©s
curl -X POST "http://localhost:8002/reconcile" \
  -H "Content-Type: application/json" \
  -d '{
    "datasets": [
      {"name": "CRM", "data": [...]},
      {"name": "ERP", "data": [...]}
    ],
    "matching_rules": {
      "email": {"weight": 0.4, "threshold": 0.8},
      "phone": {"weight": 0.3, "threshold": 0.7},
      "name": {"weight": 0.3, "threshold": 0.6}
    }
  }'

# D√©duplication
curl -X POST "http://localhost:8002/deduplicate" \
  -H "Content-Type: application/json" \
  -d '{
    "data": [...],
    "duplicate_threshold": 0.85,
    "merge_strategy": "keep_most_complete"
  }'
```

### 5. **Workflow d'Analyse RCA**

#### Via l'API RCA Service
```bash
# Analyse des causes racines
curl -X POST "http://localhost:8004/analyze" \
  -H "Content-Type: application/json" \
  -d '{
    "data": [...],
    "analysis_type": "comprehensive",
    "target_metric": "error_rate",
    "time_window": "30d",
    "correlation_threshold": 0.7
  }'

# Pr√©diction d'√©checs
curl -X POST "http://localhost:8004/predict-failure" \
  -H "Content-Type: application/json" \
  -d '{
    "data": [...],
    "prediction_horizon": "7d",
    "confidence_threshold": 0.8
  }'
```

## üìä Monitoring et Alertes

### Dashboard Grafana

1. **Acc√©der √† Grafana** : http://localhost/grafana
2. **Identifiants** : admin/admin
3. **Dashboards disponibles** :
   - **Syst√®me** : M√©triques d'infrastructure
   - **Qualit√©** : M√©triques de qualit√© des donn√©es
   - **Performance** : M√©triques de performance
   - **Business** : KPI m√©tier

### Configuration des Alertes

#### Via l'API Alertes
```bash
# Cr√©er une r√®gle d'alerte
curl -X POST "http://localhost/alerts/rules" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Score de qualit√© critique",
    "condition": "data_quality_score < 80",
    "threshold": 80.0,
    "severity": "critical",
    "enabled": true
  }'

# Consulter les alertes actives
curl -X GET "http://localhost/alerts/active"

# R√©soudre une alerte
curl -X POST "http://localhost/alerts/alerts/{alert_id}/resolve"
```

### Types d'Alertes Disponibles

1. **Qualit√© des Donn√©es**
   - Score de qualit√© < seuil
   - Taux de compl√©tude faible
   - Anomalies d√©tect√©es

2. **Performance Syst√®me**
   - Temps de r√©ponse √©lev√©
   - Utilisation CPU/M√©moire √©lev√©e
   - D√©bit de traitement faible

3. **Disponibilit√© Services**
   - Service indisponible
   - Erreurs de connexion
   - Timeout de requ√™tes

## üîß Gestion des Donn√©es

### Consultation des Donn√©es

```bash
# R√©cup√©rer des donn√©es avec filtres
curl -X GET "http://localhost/api/data?limit=100&offset=0&filters=status:active"

# Export des donn√©es
curl -X GET "http://localhost/api/data/export?format=json&filters=date:2024-01-01"

# Analytics avanc√©es
curl -X GET "http://localhost/api/analytics?metric=revenue&time_range=30d&granularity=day"
```

### Op√©rations CRUD

```bash
# Cr√©er des donn√©es
curl -X POST "http://localhost/api/data" \
  -H "Content-Type: application/json" \
  -d '{"name": "Nouveau Record", "value": 150.0}'

# Mettre √† jour
curl -X PUT "http://localhost/api/data/{record_id}" \
  -H "Content-Type: application/json" \
  -d '{"value": 200.0}'

# Supprimer
curl -X DELETE "http://localhost/api/data/{record_id}"
```

## üö® Gestion des Erreurs

### Codes d'Erreur Courants

| Code | Description | Solution |
|------|-------------|----------|
| 400 | Requ√™te malform√©e | V√©rifier le format JSON |
| 401 | Non autoris√© | V√©rifier les identifiants |
| 404 | Service non trouv√© | V√©rifier l'URL du service |
| 500 | Erreur serveur | Consulter les logs |
| 503 | Service indisponible | V√©rifier le statut du service |

### Diagnostic des Probl√®mes

```bash
# V√©rifier l'√©tat de sant√© global
curl -X GET "http://localhost/health"

# Logs d'un service sp√©cifique
docker-compose logs -f api-dashboard-service

# Logs de tous les services
docker-compose logs -f
```

## üìà Optimisation des Performances

### Recommandations

1. **Monitoring Continu**
   - Surveiller le dashboard principal
   - Configurer des alertes proactives
   - Analyser les tendances Grafana

2. **Gestion des Ressources**
   - Surveiller l'utilisation CPU/M√©moire
   - Ajuster les limites Docker si n√©cessaire
   - Optimiser les requ√™tes de base de donn√©es

3. **Qualit√© des Donn√©es**
   - Configurer des r√®gles de qualit√© appropri√©es
   - Surveiller les scores de qualit√©
   - Traiter rapidement les anomalies

### Scaling Horizontal

```bash
# Augmenter le nombre d'instances d'un service
docker-compose up -d --scale dbt-service=3
docker-compose up -d --scale quality-control-service=2
```

## üîê S√©curit√©

### Bonnes Pratiques

1. **Authentification**
   - Utiliser des cl√©s API s√©curis√©es
   - Changer les mots de passe par d√©faut
   - Impl√©menter l'authentification multi-facteurs

2. **R√©seau**
   - Utiliser HTTPS en production
   - Configurer un firewall appropri√©
   - Isoler les services sensibles

3. **Donn√©es**
   - Chiffrer les donn√©es sensibles
   - Impl√©menter des sauvegardes r√©guli√®res
   - Auditer les acc√®s aux donn√©es

## üÜò Support et D√©pannage

### Ressources de Support

1. **Documentation API** : http://localhost/docs
2. **Logs syst√®me** : `docker-compose logs`
3. **Monitoring** : http://localhost/grafana
4. **M√©triques** : http://localhost/prometheus

### Commandes de D√©pannage

```bash
# Red√©marrer un service
docker-compose restart api-dashboard-service

# Red√©marrer tous les services
docker-compose restart

# V√©rifier l'espace disque
docker system df

# Nettoyer les ressources inutilis√©es
docker system prune
```

### Contacts Support

- **Email** : support@saas-platform.com
- **Documentation** : Voir README.md
- **Issues** : GitHub Issues du projet

## üìö Ressources Suppl√©mentaires

### Documentation Technique

- [Architecture d√©taill√©e](CONCEPTION.md)
- [Guide de d√©ploiement](DEPLOYMENT-SERVER.md)
- [Configuration Kafka](KAFKA-KRAFT-SUMMARY.md)

### Formation

1. **Tutoriels API** : Utiliser la documentation Swagger interactive
2. **Exemples de code** : Voir le dossier `tests/`
3. **Cas d'usage** : Consulter les exemples dans le README

---

**üéØ Ce guide vous permet de ma√Ætriser compl√®tement la plateforme SaaS Data Platform. Pour toute question, consultez la documentation API interactive ou contactez le support.**
