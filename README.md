# üöÄ SaaS Data Platform - Plateforme de Donn√©es Conteneuris√©e

Une plateforme SaaS compl√®te de traitement et d'analyse de donn√©es utilisant des microservices conteneuris√©s avec Docker, Apache NiFi pour l'ingestion, et des services sp√©cialis√©s pour la transformation, r√©conciliation, contr√¥le qualit√© et analyse des causes racines.

## üìã Table des Mati√®res

- [Vue d'ensemble](#-vue-densemble)
- [Architecture](#-architecture)
- [Services](#-services)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [API Documentation](#-api-documentation)
- [Monitoring](#-monitoring)
- [Tests](#-tests)
- [D√©ploiement](#-d√©ploiement)
- [Contribuer](#-contribuer)

## üéØ Vue d'ensemble

Cette plateforme SaaS offre une solution compl√®te pour :

- **Ingestion de donn√©es** depuis multiples sources (CRM, ERP, Billing, CDR, OSS, fichiers externes)
- **Transformation et normalisation** des donn√©es avec dbt
- **R√©conciliation et d√©duplication** avec Zingg
- **Contr√¥le qualit√©** avec Soda
- **Analyse des causes racines** (RCA)
- **Streaming de donn√©es** avec Apache Kafka (mode KRaft)
- **API REST et Dashboard** pour visualisation et monitoring
- **Stockage historique** avec PostgreSQL

## üèóÔ∏è Architecture

### Diagramme de Flux Global

```mermaid
graph TB
    subgraph "Sources de Donn√©es"
        CRM[CRM System]
        ERP[ERP System]
        Billing[Billing System]
        CDR[CDR Data]
        OSS[OSS System]
        Files[External Files]
    end
    
    subgraph "Ingestion"
        NiFi[Apache NiFi<br/>Port: 8080]
    end
    
    subgraph "Microservices"
        DBT[dbt-service<br/>Port: 8001]
        Recon[reconciliation-service<br/>Port: 8002]
        Quality[quality-control-service<br/>Port: 8003]
        RCA[rca-service<br/>Port: 8004]
    end
    
    subgraph "API & Dashboard"
        API[api-dashboard-service<br/>Port: 8000]
        Nginx[Nginx Reverse Proxy<br/>Port: 80/443]
    end
    
    subgraph "Stockage"
        DB[(PostgreSQL Warehouse<br/>Port: 5432)]
        Redis[(Redis Cache<br/>Port: 6379)]
    end
    
    subgraph "Monitoring"
        Prometheus[Prometheus<br/>Port: 9090]
        Grafana[Grafana<br/>Port: 3000]
    end
    
    CRM --> NiFi
    ERP --> NiFi
    Billing --> NiFi
    CDR --> NiFi
    OSS --> NiFi
    Files --> NiFi
    
    NiFi --> DBT
    NiFi --> Recon
    NiFi --> Quality
    NiFi --> RCA
    
    DBT --> DB
    Recon --> DB
    Quality --> DB
    RCA --> DB
    
    API --> DBT
    API --> Recon
    API --> Quality
    API --> RCA
    API --> DB
    API --> Redis
    
    Nginx --> API
    Nginx --> NiFi
    Nginx --> Grafana
    Nginx --> Prometheus
    
    Prometheus --> API
    Prometheus --> DBT
    Prometheus --> Recon
    Prometheus --> Quality
    Prometheus --> RCA
    Prometheus --> DB
    
    Grafana --> Prometheus
```

### Diagramme de Composants

```mermaid
graph LR
    subgraph "Frontend"
        Dashboard[Web Dashboard]
        API_Client[API Client]
    end
    
    subgraph "API Gateway"
        FastAPI[FastAPI Application]
        Auth[Authentication]
        RateLimit[Rate Limiting]
    end
    
    subgraph "Business Logic"
        Transform[Data Transformation]
        Reconcile[Data Reconciliation]
        Quality[Quality Control]
        Analyze[RCA Analysis]
    end
    
    subgraph "Data Layer"
        Warehouse[(Data Warehouse)]
        Cache[(Redis Cache)]
        Files[File Storage]
    end
    
    subgraph "Infrastructure"
        Nginx[Load Balancer]
        Docker[Container Runtime]
        Monitor[Monitoring Stack]
    end
    
    Dashboard --> FastAPI
    API_Client --> FastAPI
    
    FastAPI --> Transform
    FastAPI --> Reconcile
    FastAPI --> Quality
    FastAPI --> Analyze
    
    Transform --> Warehouse
    Reconcile --> Warehouse
    Quality --> Warehouse
    Analyze --> Warehouse
    
    FastAPI --> Cache
    FastAPI --> Files
    
    Nginx --> FastAPI
    Docker --> FastAPI
    Monitor --> FastAPI
```

### Diagramme de S√©quence - Flux de Donn√©es

```mermaid
sequenceDiagram
    participant Client
    participant API
    participant NiFi
    participant DBT
    participant Quality
    participant Warehouse
    
    Client->>API: POST /data/ingest
    API->>NiFi: Forward data
    NiFi->>DBT: Transform data
    DBT->>Quality: Check quality
    Quality->>Warehouse: Store results
    Warehouse-->>Quality: Confirm storage
    Quality-->>DBT: Quality results
    DBT-->>NiFi: Transformed data
    NiFi-->>API: Processing complete
    API-->>Client: Response with status
```

## üîß Services

### 1. **api-dashboard-service** (Port 8000)
- **R√¥le** : API principale et dashboard web
- **Technologies** : FastAPI, Streamlit, Plotly
- **Fonctionnalit√©s** :
  - API REST compl√®te
  - Dashboard interactif
  - Gestion des utilisateurs et authentification
  - Monitoring des autres services
  - G√©n√©ration de rapports

### 2. **nifi-service** (Port 8080)
- **R√¥le** : Ingestion et routage des donn√©es
- **Technologies** : Apache NiFi
- **Fonctionnalit√©s** :
  - Ingestion depuis multiples sources
  - Routage intelligent des donn√©es
  - Gestion des flux de donn√©es
  - Monitoring des performances

### 3. **dbt-service** (Port 8001)
- **R√¥le** : Transformation et normalisation
- **Technologies** : dbt-core, pandas, numpy
- **Fonctionnalit√©s** :
  - Transformation de donn√©es
  - Calcul de KPI
  - Normalisation des donn√©es
  - Historique des transformations

### 4. **reconciliation-service** (Port 8002)
- **R√¥le** : R√©conciliation et d√©duplication
- **Technologies** : Zingg, scikit-learn, fuzzywuzzy
- **Fonctionnalit√©s** :
  - Matching d'entit√©s
  - D√©duplication intelligente
  - Fusion de donn√©es
  - Scores de confiance

### 5. **quality-control-service** (Port 8003)
- **R√¥le** : Contr√¥le qualit√© et d√©tection d'anomalies
- **Technologies** : Soda, scikit-learn, pandas
- **Fonctionnalit√©s** :
  - V√©rification de compl√©tude
  - Validation des donn√©es
  - D√©tection d'anomalies
  - Rapports de qualit√©

### 6. **rca-service** (Port 8004)
- **R√¥le** : Analyse des causes racines
- **Technologies** : scikit-learn, networkx, pandas
- **Fonctionnalit√©s** :
  - Analyse de corr√©lation
  - D√©tection de tendances
  - Identification des causes racines
  - Recommandations

### 7. **warehouse-service** (Port 5432)
- **R√¥le** : Stockage historique et audit
- **Technologies** : PostgreSQL
- **Fonctionnalit√©s** :
  - Stockage des donn√©es transform√©es
  - Historique des op√©rations
  - M√©triques syst√®me
  - Logs d'audit

### 8. **kafka** (Port 9092) - Mode KRaft
- **R√¥le** : Streaming de donn√©es et messagerie
- **Technologies** : Apache Kafka 7.4.0 (mode KRaft)
- **Fonctionnalit√©s** :
  - Streaming de donn√©es en temps r√©el
  - Messagerie asynchrone entre services
  - Topics pour √©v√©nements CDR, alertes, m√©triques
  - Architecture simplifi√©e sans ZooKeeper

## üöÄ Installation

### Pr√©requis

- Docker 20.10+
- Docker Compose 2.0+
- 8 GB RAM minimum
- 20 GB espace disque libre

### Installation Rapide

```bash
# Cloner le projet
git clone <repository-url>
cd saas

# Construire et d√©marrer tous les services
docker-compose up --build

# V√©rifier que tous les services sont d√©marr√©s
docker-compose ps
```

### Installation D√©taill√©e

```bash
# 1. Construire les images Docker
docker-compose build

# 2. D√©marrer la base de donn√©es et Redis
docker-compose up -d warehouse-service redis

# 3. Attendre que la base soit pr√™te
docker-compose logs warehouse-service

# 4. D√©marrer les microservices
docker-compose up -d dbt-service reconciliation-service quality-control-service rca-service

# 5. D√©marrer NiFi et l'API Dashboard
docker-compose up -d nifi-service api-dashboard-service

# 6. D√©marrer le monitoring
docker-compose up -d prometheus grafana

# 7. D√©marrer le reverse proxy
docker-compose up -d nginx
```

### Variables d'Environnement

Cr√©er un fichier `.env` √† la racine :

```env
# Base de donn√©es
POSTGRES_DB=data_warehouse
POSTGRES_USER=warehouse_user
POSTGRES_PASSWORD=warehouse_password

# API Dashboard
SECRET_KEY=your-secret-key-here-change-in-production
DEBUG=false

# Monitoring
GRAFANA_ADMIN_PASSWORD=admin
PROMETHEUS_RETENTION=30d

# Redis
REDIS_PASSWORD=redis_password
```

## üìñ Utilisation

### Acc√®s aux Services

| Service | URL | Description |
|---------|-----|-------------|
| Dashboard Principal | http://localhost | Interface web principale |
| API Documentation | http://localhost/docs | Documentation Swagger |
| NiFi | http://localhost/nifi | Interface NiFi |
| Grafana | http://localhost/grafana | Monitoring (admin/admin) |
| Prometheus | http://localhost/prometheus | M√©triques |

### Utilisation de l'API

#### Ingestion de Donn√©es

```bash
# Ingestion via API
curl -X POST "http://localhost/data/ingest" \
  -H "Content-Type: application/json" \
  -d '[
    {
      "id": "1",
      "name": "John Doe",
      "email": "john@example.com",
      "value": 100.50
    }
  ]'
```

#### Transformation de Donn√©es

```bash
# Transformation via dbt-service
curl -X POST "http://localhost:8001/transform" \
  -H "Content-Type: application/json" \
  -d '{
    "data": [...],
    "transformation_type": "normalize",
    "parameters": {
      "normalize_numeric": true,
      "trim_strings": true
    }
  }'
```

#### Contr√¥le Qualit√©

```bash
# Contr√¥le qualit√© via quality-control-service
curl -X POST "http://localhost:8003/check" \
  -H "Content-Type: application/json" \
  -d '{
    "data": [...],
    "quality_rules": [
      {
        "type": "required_field",
        "field": "email"
      }
    ],
    "check_completeness": true,
    "check_validity": true
  }'
```

### Utilisation du Dashboard

1. **Acc√©der au dashboard** : http://localhost
2. **Voir l'√©tat des services** : Widget "√âtat des Services"
3. **Consulter les m√©triques** : Widget "Score de Qualit√©"
4. **Surveiller les alertes** : Section "Alertes"
5. **G√©n√©rer des rapports** : Section "Rapports"

## üìö API Documentation

### Endpoints Principaux

#### API Dashboard (Port 8000)

| Endpoint | M√©thode | Description |
|----------|---------|-------------|
| `/health` | GET | √âtat de sant√© du syst√®me |
| `/dashboard/data` | GET | Donn√©es du dashboard |
| `/data/ingest` | POST | Ingestion de donn√©es |
| `/kpis` | GET | KPI syst√®me |
| `/alerts/configure` | POST | Configuration d'alertes |
| `/metrics/overview` | GET | Vue d'ensemble des m√©triques |

#### Service DBT (Port 8001)

| Endpoint | M√©thode | Description |
|----------|---------|-------------|
| `/health` | GET | √âtat du service |
| `/transform` | POST | Transformation de donn√©es |
| `/kpi/calculate` | POST | Calcul de KPI |
| `/normalize` | POST | Normalisation |
| `/metrics` | GET | M√©triques du service |

#### Service R√©conciliation (Port 8002)

| Endpoint | M√©thode | Description |
|----------|---------|-------------|
| `/health` | GET | √âtat du service |
| `/reconcile` | POST | R√©conciliation de donn√©es |
| `/match` | POST | Matching d'entit√©s |
| `/deduplicate` | POST | D√©duplication |
| `/validate-matches` | POST | Validation des matches |

#### Service Contr√¥le Qualit√© (Port 8003)

| Endpoint | M√©thode | Description |
|----------|---------|-------------|
| `/health` | GET | √âtat du service |
| `/check` | POST | Contr√¥le qualit√© |
| `/detect-anomalies` | POST | D√©tection d'anomalies |
| `/validate-schema` | POST | Validation de sch√©ma |
| `/check-completeness` | POST | V√©rification compl√©tude |

#### Service RCA (Port 8004)

| Endpoint | M√©thode | Description |
|----------|---------|-------------|
| `/health` | GET | √âtat du service |
| `/analyze` | POST | Analyse RCA |
| `/correlation` | POST | Analyse de corr√©lation |
| `/trend-analysis` | POST | Analyse de tendances |
| `/predict-failure` | POST | Pr√©diction d'√©checs |

## üìä Monitoring

### M√©triques Disponibles

- **Performance** : Temps de r√©ponse, d√©bit, utilisation CPU/M√©moire
- **Qualit√©** : Scores de qualit√©, taux d'erreur, compl√©tude
- **Business** : KPI m√©tier, volumes de donn√©es, alertes
- **Infrastructure** : √âtat des services, connectivit√©, stockage
- **Kafka** : D√©bit des topics, latence, consommation, production

## üîÑ Kafka Streaming (Mode KRaft)

### Configuration

Kafka fonctionne en mode KRaft (sans ZooKeeper) pour une architecture simplifi√©e :

```bash
# D√©marrer Kafka
make kafka-up

# V√©rifier le statut
make kafka-test

# Initialiser les topics
make kafka-init-topics

# Lister les topics
make kafka-topics
```

### Topics Disponibles

| Topic | Description | Partitions |
|-------|-------------|------------|
| `cdr-events` | √âv√©nements CDR | 3 |
| `alerts` | Alertes syst√®me | 3 |
| `metrics` | M√©triques de performance | 3 |
| `quality-events` | √âv√©nements de qualit√© | 3 |
| `reconciliation-events` | √âv√©nements de r√©conciliation | 3 |
| `rca-events` | √âv√©nements d'analyse RCA | 3 |
| `dbt-events` | √âv√©nements de transformation | 3 |
| `audit-logs` | Logs d'audit | 3 |

### Utilisation

```bash
# Produire un message
make kafka-produce TOPIC=test-topic MESSAGE="Hello Kafka"

# Consommer des messages
make kafka-consume TOPIC=test-topic

# Tester la connectivit√©
make kafka-test
```

### Scripts PowerShell (Windows)

```powershell
# Initialiser les topics
.\scripts\init-kafka-topics.ps1

# Tester Kafka
.\scripts\test-kafka-kraft.ps1
```

### Dashboards Grafana

1. **Dashboard Syst√®me** : M√©triques d'infrastructure
2. **Dashboard Qualit√©** : M√©triques de qualit√© des donn√©es
3. **Dashboard Performance** : M√©triques de performance
4. **Dashboard Business** : KPI m√©tier

### Alertes Configurables

- Score de qualit√© < seuil
- Taux d'erreur > seuil
- Service indisponible
- D√©lai de traitement > seuil
- Utilisation ressources > seuil

## üß™ Tests

### Ex√©cution des Tests

```bash
# Tests unitaires
pytest tests/unit/ -v

# Tests d'int√©gration
pytest tests/integration/ -v

# Tests avec couverture
pytest --cov=. --cov-report=html

# Tests sp√©cifiques
pytest tests/unit/test_dbt_service.py::TestDataTransformationService -v
```

### Structure des Tests

```
tests/
‚îú‚îÄ‚îÄ conftest.py              # Configuration globale
‚îú‚îÄ‚îÄ requirements.txt         # D√©pendances de test
‚îú‚îÄ‚îÄ unit/                   # Tests unitaires
‚îÇ   ‚îî‚îÄ‚îÄ test_dbt_service.py
‚îî‚îÄ‚îÄ integration/            # Tests d'int√©gration
    ‚îî‚îÄ‚îÄ test_api_integration.py
```

### Couverture de Code

- **Objectif** : 80% minimum
- **Rapport HTML** : `htmlcov/index.html`
- **Rapport terminal** : Affich√© apr√®s ex√©cution

## üöÄ D√©ploiement

### D√©ploiement en Production

```bash
# 1. Configuration production
cp .env.production .env

# 2. Build optimis√©
docker-compose -f docker-compose.prod.yml build

# 3. D√©ploiement
docker-compose -f docker-compose.prod.yml up -d

# 4. V√©rification
docker-compose -f docker-compose.prod.yml ps
```

### Configuration Production

- SSL/TLS avec certificats
- Base de donn√©es externalis√©e
- Monitoring avanc√©
- Logs centralis√©s
- Sauvegardes automatiques

### Scaling Horizontal

```bash
# Scale des services
docker-compose up -d --scale dbt-service=3
docker-compose up -d --scale quality-control-service=2
```

## üîß Maintenance

### Sauvegardes

```bash
# Sauvegarde base de donn√©es
docker exec warehouse-service pg_dump -U warehouse_user data_warehouse > backup.sql

# Sauvegarde volumes
docker run --rm -v saas_postgres-data:/data -v $(pwd):/backup alpine tar czf /backup/postgres-backup.tar.gz /data
```

### Logs

```bash
# Logs en temps r√©el
docker-compose logs -f

# Logs d'un service sp√©cifique
docker-compose logs -f api-dashboard-service

# Logs avec timestamps
docker-compose logs -f -t
```

### Mise √† Jour

```bash
# Mise √† jour des images
docker-compose pull
docker-compose up -d

# Rebuild complet
docker-compose down
docker-compose up --build -d
```

## ü§ù Contribuer

### Guidelines

1. Fork le projet
2. Cr√©er une branche feature (`git checkout -b feature/AmazingFeature`)
3. Commit les changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

### Standards de Code

- **Python** : PEP 8, Black formatter
- **Tests** : Couverture 80% minimum
- **Documentation** : Docstrings et README
- **Commits** : Messages clairs et descriptifs

## üìÑ Licence

Ce projet est sous licence MIT. Voir le fichier `LICENSE` pour plus de d√©tails.

## üìû Support

- **Issues** : [GitHub Issues](link-to-issues)
- **Documentation** : [Wiki](link-to-wiki)
- **Email** : support@saas-platform.com

## üéØ Roadmap

### Version 2.0
- [ ] Support multi-tenant
- [ ] Machine Learning int√©gr√©
- [ ] Streaming en temps r√©el
- [ ] Interface mobile

### Version 2.1
- [ ] Int√©gration cloud native
- [ ] Auto-scaling intelligent
- [ ] Analytics avanc√©s
- [ ] API GraphQL

---

**D√©velopp√© avec ‚ù§Ô∏è pour la communaut√© open source**
